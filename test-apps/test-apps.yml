#
# General configuration
#
config:
  results_dir: ../results
  materialize_to: ./test-apps-materialized.yml
  trace:
    full_trace: true
    save_json: false
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # tracing does not require multiple repetitions
    repetitions: 1
    # skip certain kernels used for cache invalidation
    skip_kernel_prefixes:
      - gpucachesim_skip
  accelsim_trace:
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # tracing does not require multiple repetitions
    repetitions: 1
  profile:
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # profiling has very high statistical error
    # also, we use repetitions to warm up the GPU
    repetitions: 10
    keep_log_file: true
  # for simulation, we do not set a limit on concurrency
  exec_simulate:
    # No concurrency limit for now (until we implement multi-threading)
    concurrency: 1 # null
    repetitions: 1
    # l2_prefill: true
  simulate:
    # No concurrency limit for now (until we implement multi-threading)
    concurrency: 1 # null
    repetitions: 2
    # l2_prefill: true
    # this is added to all inputs
    inputs:
      mode:
        - serial
        - deterministic
        - nondeterministic
        # - nondeterministic_interleave
      threads: [4, 8]
      run_ahead: [5, 10]
      num_clusters: [28, 56]
      # cores_per_cluster: [1, 4, 8]
      cores_per_cluster: [1, 8]
      memory_only: [false, true]
      exclude:
        - mode: serial
          threads: 8
        - mode: serial
          run_ahead: 10
        - mode: deterministic
          run_ahead: 10
        - num_clusters: 56
          cores_per_cluster: 8
        - num_clusters: 56
          cores_per_cluster: 8
  # for accelsim simulation, we do not set a limit on concurrency
  accelsim_simulate:
    # No concurrency limit as accelsim is single threaded.
    # Also, it is spawned as a sub process to avoid global state related issues.
    # However, we do not run concurrently to increase accuracy of execution time measurements
    concurrency: 1
    repetitions: 2
    # simulation configurations
    config_dir: ../accelsim/gtx1080/
    # config: ../accelsim/gtx1080/gpgpusim.config
    config: ../accelsim/gtx1080/gpgpusim.original.config
    trace_config: ../accelsim/gtx1080/gpgpusim.trace.config
    inter_config: ../accelsim/gtx1080/config_pascal_islip.icnt
  playground_simulate:
    # BUG: due to static global state in intersim2, can only run one benchmark at a time for now
    concurrency: 1
    repetitions: 1
    # simulation configurations
    config_dir: ../accelsim/gtx1080/
    # config: ../accelsim/gtx1080/gpgpusim.config
    config: ../accelsim/gtx1080/gpgpusim.original.config
    trace_config: ../accelsim/gtx1080/gpgpusim.trace.config
    inter_config: ../accelsim/gtx1080/config_pascal_islip.icnt
#
# Benchmarks
#
benchmarks:
  vectorAdd:
    path: ./vectoradd
    executable: vectoradd_l1_enabled
    # executable: vectoradd_l1_disabled
    inputs:
      dtype: [32, 64]
      # at a size of 500000 we have 3*500k*4 bytes = 6MB of floats,
      # which is enough to saturate the 3MB L2 cache
      length: [100, 1000, 10000, 20000, 100000, 500000]
    args: "{{ input.length }} {{ input.dtype }}"
    simulate:
      traces_dir: "vectorAdd/vectorAdd-dtype-{{ input.dtype }}-length-{{ input.length }}/trace"
      accelsim_traces_dir: "vectorAdd/vectorAdd-dtype-{{ input.dtype }}-length-{{ input.length }}/accelsim-trace"
  simple_matrixmul:
    path: ./simple_matrixmul
    executable: matrixmul
    inputs:
      dtype: [32]
      m: [32, 64, 128]
      n: [32, 64, 128]
      p: [32, 64, 128]
      include:
        - { m: 512, n: 32, p: 512, dtype: 32 } # included because of size (parallel speedup)
        - { m: 128, n: 512, p: 128, dtype: 32 } # included because large n leading to lower L1 hit rate
        # - { m: 32, n: 1024, p: 32, dtype: 32 }
      #   - { m: 32, n: 2048, p: 32, dtype: 32 }
      #   - { m: 32, n: 4096, p: 32, dtype: 32 }
    # (m x n) x (n x p)
    args: "{{ input.m }} {{ input.n }} {{ input.p }} {{ input.dtype }}"
    simulate:
      # l2_prefill: false
      traces_dir: "simple_matrixmul/simple_matrixmul-dtype-{{ input.dtype }}-m-{{ input.m }}-n-{{ input.n }}-p-{{ input.p }}/trace"
      accelsim_traces_dir: "simple_matrixmul/simple_matrixmul-dtype-{{ input.dtype }}-m-{{ input.m }}-n-{{ input.n }}-p-{{ input.p }}/accelsim-trace"
  matrixmul:
    path: ./matrixmul
    executable: matrixmul
    inputs:
      dtype: [32]
      rows: [32, 64, 128, 256, 512]
      # exclude:
      #   - rows: 512
    # (rows x rows) x (rows x rows)
    args: "{{ input.rows }} {{ input.dtype }}"
    simulate:
      traces_dir: "matrixmul/matrixmul-dtype-{{ input.dtype }}-rows-{{ input.rows }}/trace"
      accelsim_traces_dir: "matrixmul/matrixmul-dtype-{{ input.dtype }}-rows-{{ input.rows }}/accelsim-trace"
  # CUDA 10 transpose (modified to allow running individual implementations)
  transpose:
    path: ./transpose
    executable: transpose
    inputs:
      # must be square matrix
      # dim: [128, 256, 512, 1024]
      dim: [128, 256, 512]
      variant:
        - "naive"
        - "coalesced"
        # optimized is almost identical to coalesced.
        # it is supposed to reduce bank conflicts but we see no effect on cycles when profiling
        # - "optimized"
      include:
        - repeat: 1
    args: "-variant={{ input.variant }} -dimX={{ input.dim }} -dimY={{ input.dim }} -repeat=0"
    # args: -variant=naive -dimX=512 -dimY=512 -repeat=0
    # args: "-variant={{ input.variant }} -dimX={{ input.dim }} -dimY={{ input.dim }} -repeat={{ input.repeat }}"
    simulate:
      traces_dir: "transpose/transpose-dim-{{ input.dim }}-repeat-{{ input.repeat }}-variant-{{ input.variant }}/trace"
      accelsim_traces_dir: "transpose/transpose-dim-{{ input.dim }}-repeat-{{ input.repeat }}-variant-{{ input.variant }}/accelsim-trace"
  babelstream:
    path: ./BabelStream
    executable: CUDAStream
    # - args: --arraysize 1024 --numtimes 1
    # - args: --arraysize 1024 --numtimes 2
    # - args: --arraysize 10240 --numtimes 1
    # - args: --arraysize 102400 --numtimes 1

    inputs:
      size: [1024, 10240, 102400]
    args: "--arraysize {{ input.size }} --numtimes 1"
    exec_driven_simulate:
      enabled: false
    simulate:
      traces_dir: "babelstream/babelstream-size-{{ input.size }}/trace"
      accelsim_traces_dir: "babelstream/babelstream-size-{{ input.size }}/accelsim-trace"
  # parboil_bfs:
  #   path: ./parboil/bfs/src/cuda
  #   executable: CUDAStream
  #   inputs: {}
  #   # size: [1024, 10240, 102400]
  #   # args: "--arraysize {{ input.size }} --numtimes 1"
  #   args: ""
  #   exec_driven_simulate:
  #     enabled: false
  #   # simulate:
  #   #   traces_dir: "babelstream/babelstream-size-{{ input.size }}/trace"
  #   #   accelsim_traces_dir: "babelstream/babelstream-size-{{ input.size }}/accelsim-trace"
